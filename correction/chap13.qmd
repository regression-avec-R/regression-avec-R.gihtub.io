---
title: "13 Régularisation de la vraisemblance"
toc: true
---

```{r,child='../_preamble.qmd'}
```

::: {#exr-13-1 name="Questions de cours"}
1.  A, B
2.  C
3.  A
4.  C, D
:::

::: {#exr-13-2 name="Lasso sur des données centrées réduites"}
```{r}
library(bestglm)
data(SAheart)
SAheart.X <- model.matrix(chd~.,data=SAheart)[,-1]
SAheart.Y <- SAheart$chd 
library(glmnet)
mod.lasso <- glmnet(SAheart.X,SAheart.Y,family="binomial",alpha=1)
```

1.  

    ```{r}
    lam.lasso <- mod.lasso$lambda
    lam <- lam.lasso[50]
    coef(mod.lasso,s=lam)
    ```

2.  

    ```{r}
    mu <- apply(SAheart.X,2,mean)
    sig <- apply(SAheart.X,2,sd)
    mu.mat <- matrix(rep(mu,nrow(SAheart.X)),nrow=nrow(SAheart.X),byrow=T)
    sig.mat <- matrix(rep(sig,nrow(SAheart.X)),nrow=nrow(SAheart.X),byrow=T)
    SAheart.X.cr <- (SAheart.X-mu.mat)/sig.mat
    mod.lasso1 <- glmnet(SAheart.X.cr,SAheart.Y,family="binomial",alpha=1)
    ```

3.  

    ```{r}
    lam1 <- mod.lasso1$lambda[50]
    coef(mod.lasso1,s=lam1)[-1]/sig
    ```

:::

::: {#exr-13-3 name="Comparaison de méthodes et courbes ROC"}

1.  On importe les données et on les sépare en un échantillon d'apprentissage et de test.

    ```{r}
    df <- read.csv("../donnees/logit_ridge_lasso.csv")
    set.seed(1254)
    perm <- sample(nrow(df))
    dapp <- df[perm[1:300],]
    dtest <- df[perm[301:500],]
    ```

2.  On construit les modèles demandés sur les données d'apprentissage uniquement.

    ```{r,cache=TRUE}
    logit <- glm(Y~.,data=dapp,family="binomial")
    logit.step <- step(logit,direction="backward",trace=0)
    ```
    
    
    ```{r}
    Xapp <- model.matrix(Y~.,data=dapp)[,-1]
    Xtest <- model.matrix(Y~.,data=dtest)[,-1]
    Yapp <- dapp$Y
    Ytest <- dtest$Y
    ```
    
    ```{r}
    lasso1 <- cv.glmnet(Xapp,Yapp,family="binomial",alpha=1)
    ridge1 <- cv.glmnet(Xapp,Yapp,family="binomial",alpha=0,lambda=exp(seq(-6,-1,length=100)))
    lasso2 <- cv.glmnet(Xapp,Yapp,family="binomial",alpha=1,type.measure = "auc")
    ridge2 <- cv.glmnet(Xapp,Yapp,family="binomial",alpha=0,type.measure = "auc",lambda=exp(seq(-3,2,length=100)))
    ```



3.  

    ```{r}
    library(tidyverse)
    score <- data.frame(logit=predict(logit,newdata=dtest,type="response"),
                        step=predict(logit.step,newdata=dtest,type="response"),
                        lasso1=as.vector(predict(lasso1,type="response",newx=Xtest)),
                        ridge1=as.vector(predict(ridge1,type="response",newx=Xtest)),
                        lasso2=as.vector(predict(lasso2,type="response",newx=Xtest)),
                        ridge2=as.vector(predict(ridge2,type="response",newx=Xtest))) %>% 
      mutate(obs=Ytest) %>% gather(key="Methode",value="score",-obs)
    
    ```

    ```{r}
    library(plotROC)
    ggplot(score)+aes(m=score,d=obs,color=Methode)+geom_roc()+theme_classic()
    ```


3.  

    ```{r}
    library(tidymodels)
    score %>% 
      group_by(Methode) %>% 
      mutate(obs=as.factor(obs)) %>%
      roc_auc(obs,score,event_level = "second") %>%
      select(Methode,.estimate) %>%
      arrange(desc(.estimate))
    ```

:::

::: {#exr-13-4 name="Surapprentissage"}
1.  

    ```{r}
    score.app <- data.frame(logit=predict(logit,newdata=dapp,type="response"),
                        step=predict(logit.step,newdata=dapp,type="response"),
                        lasso1=as.vector(predict(lasso1,type="response",newx=Xapp)),
                        ridge1=as.vector(predict(ridge1,type="response",newx=Xapp)),
                        lasso2=as.vector(predict(lasso2,type="response",newx=Xapp)),
                        ridge2=as.vector(predict(ridge2,type="response",newx=Xapp))) %>% 
      mutate(obs=Yapp) %>% gather(key="Methode",value="score",-obs) 
    ```

2.  On prédit 1 si la probabilité que **Y** soit égale à 1 est supérieure ou égale à 0.5 :

    ```{r}
    prev.app <- score.app %>% mutate(prev=round(score))
    prev.app %>% group_by(Methode) %>% summarise(Err=mean(prev!=obs)) %>% arrange(Err)
    ```

3.  On fait de même avec l'échantillon test.

    ```{r}
    prev.test <- score %>% mutate(prev=round(score))
    prev.test %>% group_by(Methode) %>% summarise(Err=mean(prev!=obs)) %>% arrange(Err)
    ```


    Sur les données d'apprentissage ce sont les modèles logistiques complets et construits avec **step** qui ont les plus petites erreurs. Ces modèles souffrent de sur-apprentissage : ils ajustent très bien les données d'apprentissage mais ont du mal à bien prédire de nouveaux individus.


:::
