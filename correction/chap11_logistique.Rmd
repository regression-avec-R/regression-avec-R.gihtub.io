---
title: "Chapitre 11 : régression logistique"
layout: default
output: 
  html_document:
    css: styles.css
    toc: true
    toc_float: true
    layout: default
header-includes:
  - \newcommand{\prob}{\mathbf P}
  - \newcommand{\esp}{\mathbf E}
  - \newcommand{\var}{\mathbf V}
  - \newcommand{\ind}{\mathbf 1}

#  html_document:
#    toc: true
#    toc_depth: 3
#  github_document:
#    toc: true
#    toc_depth: 3
---



## Exercice 1

  1. A
  2. A
  3. B
  4. A
  5. A
  6. A
  7. B
  8. A
  9. C
  10. D
  11. A, B
  12. C
  
  
## Exercice 2

1. On génère l'échantillon.

    ```{r}
n <- 100
set.seed(48967365)
X <- sample(c("A","B","C"),100,replace=TRUE)
Y <- rep(0,n)
set.seed(487365)
Y[X=="A"] <- rbinom(sum(X=="A"),size=1,prob=0.95)
set.seed(4878365)
Y[X=="B"] <- rbinom(sum(X=="B"),size=1,prob=0.95)
set.seed(4653965)
Y[X=="C"] <- rbinom(sum(X=="C"),size=1,prob=0.05)
Y <- factor(Y)
donnees<-data.frame(Y,X)
    ```

2. On ajuste le modèle avec les contraintes par défaut. 
    ```{r}
model1 <- glm(Y~X,data=donnees,family=binomial)
summary(model1)
```
On obtient les résultats du **test de Wald** sur la nullité des paramètres $\beta_0,\beta_2$ et $\beta_3$.

3. On change la modalité de référence.
    ```{r}
model2 <- glm(Y~C(X,base=3),data=donnees,family=binomial)
summary(model2)
```
On obtient les résultats du **test de Wald** sur la nullité des paramètres $\beta_0,\beta_1$ et $\beta_2$.

4. On remarque que dans **model1** on accepte la nullité de $\beta_2$ alors qu'on la rejette dans **model2**. Ceci est logique dans la mesure où ces tests dépendent de la contrainte identifiante choisie. Dans **model1** le test de nullité de $\beta_2$ permet de vérifier si $B$ à un effet similaire à $A$ sur $Y$. Dans **model2**, on compare l'effet de $B$ à celui de $C$. On peut donc conclure $A$ et $B$ ont des effets proches sur $Y$ alors que $B$ et $C$ ont un impact différent. Ceci est logique vu la façon dont les données ont été générées.

5. Tester l'effet global de $X$ sur $Y$ revient à tester si les coefficients $\beta_1,\beta_2$ et $\beta_3$ sont égaux, ce qui, compte tenu des contraintes revient à considérer les hypothèses nulles :
    * $\beta_2=\beta_3=0$ dans **model1** ;
    * $\beta_1=\beta_2=0$ dans **model2**.
On peut effectuer les tests de **Wald** ou du **rapport de vraisemblance**. On obtient les résultats du **rapport de vraisemblance** avec :

    ```{r message=FALSE, warning=FALSE}
library(car)
Anova(model1,type=3,test.statistic="LR")
Anova(model2,type=3,test.statistic="LR")
```
On remarque ici que ces deux tests sont identiques : ils ne dépendent pas de la contrainte identifiante choisie.

## Exercice 3

1. On génère l'échantillon demandé.
    ```{r}
set.seed(1234)
X <- c(runif(50,-1,0),runif(50,0,1))
set.seed(5678)
Y <- c(rep(0,50),rep(1,50))
df <- data.frame(X,Y)
```


2. Le graphe s'obtient avec :
    ```{r}
beta <- seq(0,100,by=0.01)
log_vrais <- function(X,Y,beta){
  LV <- rep(0,length(beta))
  for (i in 1:length(beta)){
    Pbeta <- exp(beta[i]*X)/(1+exp(beta[i]*X))
    LV[i] <- sum(Y*X*beta[i]-log(1+exp(X*beta[i])))
#    gradln[i] <- t(Xb)%*%(Yb-Pbeta)
  }
  return(LV)
}
LL <- log_vrais(X,Y,beta)
plot(beta,LL,type="l")
```

3. On obtient un avertissement qui nous dit que l'algorithme d'optimisation n'a pas convergé.
    ```{r}
model <- glm(Y~X-1,data=df,family="binomial")
model$coef
```

4. Le changement proposé supprime la séparabilité des données. On obtient bien un maximum fini pour cette nouvelle vraisemblance.

    ```{r}
Y1 <- Y;Y1[1] <- 1
LL1 <- log_vrais(X,Y1,beta)
plot(beta,LL1,type="l")
model1 <- glm(Y1~X-1,family="binomial")
model1$coef
```


## Exercice 4
Le gradient de la log-vraisemblance en $\beta$ est donné par $\nabla \mathcal L(Y,\beta)=X'(Y-P_\beta)$. Sa $j$ème composante vaut
$$\frac{\partial\mathcal L}{\partial\beta_j}(\beta)=\sum_{i=1}^nx_{ij}(y_i-p_\beta(x_i)).$$

On peut donc calculer la drivée par rapport à $\beta_\ell$ :
\begin{align*}
\frac{\partial\mathcal L}{\partial\beta_j\partial\beta_\ell}(\beta)= & \frac{\partial}{\partial\beta_\ell}\left[
\sum_{i=1}^nx_{ij}(y_i-\frac{\exp(x_i'\beta)}{1+\exp(x_i'\beta)})\right] \\
=& -\sum_{i=1}^nx_{ij}x_{i\ell}\frac{\exp(x_i'\beta)}{[1+\exp(x_i'\beta)]^2} \\
=& -\sum_{i=1}^nx_{ij}x_{i\ell}p_\beta(x_i)(1-p_\beta(x_i)).
\end{align*}
Matriciellement on déduit donc que la hessienne vaut
$$\nabla^2\mathcal L(Y,\beta)=-X'W_\beta X,$$
où $W_\beta$ est la matrice $n\times n$ diagonale dont le $i$ème terme de la diagonale vaut $p_\beta(x_i)(1-p_\beta(x_i))$.
Par ailleurs, comme pour tout $i=1,\dots,n$, on a $p_\beta(x_i)(1-p_\beta(x_i))>0$ et que $X$ est de plein rang, on déduit que $X'W_\beta X$ est définie positive et par conséquent que la hessienne est définie négative.


## Exercice 5

On importe les données
```{r}
panne <- read.table("panne.txt",header=T)
head(panne)
```


1. La commande
    ```{r}
model <- glm(etat~.,data=panne,family=binomial)
model
```
ajuste le modèle
$$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\beta_0+\beta_1x_1+\beta_2\mathsf{1}_{x_2=B}+\beta_3\mathsf{1}_{x_2=C}$$
où $x_1$ et $x_2$ désigne respectivement les variables **age** et **marque**. On obtient les estimateurs avec
    ```{r}
coef(model)
```

2. Il s'agit des tests de Wald pour tester l'effet des variables dans le modèle. Pour l'effet de marque, on va par exemple tester 
$$H_0:\beta_2=\beta_3=0\quad\text{contre}\quad H_1:\beta_2\neq 0\text{ ou }\beta_3\neq 0.$$
Sous $H_0$ la statistique de Wald suit une loi du $\chi^2$ à 4-2=2 degrés de liberté. Pour le test de la variable **age** le nombre de degrés de liberté manquant est 1. On retrouve cela dans la sortie
    ```{r}
library(car)
Anova(model,type=3,test.statistic="Wald")
```

3. Il s'agit cett fois du test du rapport de vraisemblance. Les degrés de liberté manquants sont identiques.

    ```{r}
Anova(model,type=3,test.statistic="LR")
```



4. 
    a). Le modèle s'écrit
  $$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\beta_0+\beta_1\mathsf{1}_{x_2=A}+\beta_2\mathsf{1}_{x_2=B}.$$

    b). Le modèle ajusté ici est
    $$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\gamma_0+\gamma_1\mathsf{1}_{x_2=B}+\gamma_2\mathsf{1}_{x_2=C}.$$
Par identification on a
$$\begin{cases}
\beta_0+\beta_1=\gamma_0 \\
\beta_0+\beta_2=\gamma_0+\gamma_1 \\
\beta_0=\gamma_0+\gamma_2 \\
\end{cases}
\Longleftrightarrow
\begin{cases}
\beta_0=\gamma_0+\gamma_2 \\
\beta_1=-\gamma_2 \\
\beta_2=\gamma_1-\gamma_2 \\
\end{cases}
\Longrightarrow
\begin{cases}
\widehat\beta_0=-0.92 \\
\widehat\beta_1=1.48 \\
\widehat\beta_2=1.05 \\
\end{cases}$$
On peut retrouver ces résultats avec
    ```{r}
glm(etat~C(marque,base=3),data=panne,family="binomial")
```


5. Il y a interaction si l'age agit différemment sur la panne en fonction de la marque.

6. Le modèle ajusté sur **R** est
$$\log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\delta_0+\delta_1\mathsf{1}_{x_2=B}+\delta_2\mathsf{1}_{x_2=C}+\delta_3x_1+\delta_4x_1\mathsf{1}_{x_2=B}+\delta_5x_1\mathsf{1}_{x_2=C}.$$
On obtient ainsi par identification :
$$\begin{cases}
\alpha_0=\delta_0\\
\alpha_1=\delta_3\\
\beta_0=\delta_0+\delta_1\\
\beta_1=\delta_3+\delta_4\\
\gamma_0=\delta_0+\delta_2\\
\gamma_1=\delta_3+\delta_5
\end{cases}$$
On peut ainsi en déduire les valeurs des estimateurs que l'on peut retrouver avec la commande :
    ```{r}
glm(etat~-1+marque+marque:age,data=panne,family="binomial")
```


## Exercice 6

```{r}
df <- read.csv("logit_ex6.csv")
mod <- glm(Y~.,data=df,family=binomial)
mod1 <- glm(Y~X1,data=df,family=binomial)
summary(mod)
summary(mod1)
```


On remarque que la nullité du paramètre associé à **X1** est accepté dans le modèle avec uniquement **X1** alors qu'elle est refusée lorsqu'on considère **X1** et **X2** dans le modèle.

## Exercice 7

1. Le modèle s'écrit
$$log\left(\frac{p_\beta(x)}{1-p_\beta(x)}\right)=\beta_0+\beta_1x.$$

2. La log vraisemblance s'obtient avec
    ```{r}
p <- c(0.76,0.4,0.6,0.89,0.35)
Y <- c(1,0,0,1,1)
L1 <- log(prod(p^Y*(1-p)^(1-Y)))
L1
```

3. 
  
    a). On calcule les écart-type des estimateurs
    ```{r}
X1 <- c(0.47,-0.55,-0.01,1.07,-0.71)
X <- matrix(c(rep(1,5),X1),ncol=2)
W <- diag(p*(1-p))
SIG <- solve(t(X)%*%W%*%X)
sig <- sqrt(diag(SIG))
sig
```
On en déduit les statistiques de test :
    ```{r}
beta <- c(0.4383,1.5063)
beta/sig
```

    b). On peut faire le test de Wald et du rapport de vraisemblance. 
  
    c). La statistique de test vaut 0.8632411, on obtient donc la probabilité critique
    ```{r}
2*(1-pnorm(0.8632411))
```
On peut également effectuer un test du rapport de vraisemblance. Le modèle null sans **X1** a pour log-vraisemblance

    ```{r}
p0 <- 3/5
L0 <- log(prod(p0^Y*(1-p0)^(1-Y)))
L0
```
La statistique de test vaut donc

    ```{r}
2*(L1-L0)
```
et la probabilité critique vaut

    ```{r}
1-pchisq(2*(L1-L0),df=1)
```
On peut retrouver (aux arrondis près) les résultats de l'exercice avec

    ```{r}
X <- c(0.47,-0.55,-0.01,1.07,-0.71)
Y <- c(1,0,0,1,1)
df <- data.frame(X,Y)
model <- glm(Y~X,data=df,family="binomial")
logLik(model)
Anova(model,type=3,test.statistic = "Wald")
Anova(model,type=3,test.statistic = "LR")
```



## Exercice 8

1. Les variables $(y_t,t=1,\dots,y_T)$ étant indépendantes et de loi binomiales $B(n_t,p_t)$, la log-vraisemblance est donnée par
\begin{align*}
\mathcal L_{\text{sat}}(Y,p)= & \log\left(\prod_{t=1}^T
\begin{pmatrix}
n_t\\
\tilde y_t
\end{pmatrix}
p_t^{\tilde y_t}(1-p_t)^{n_t-\tilde y_t}\right) \\
= &
\sum_{t=1}^T\left(\log
\begin{pmatrix}
n_t\\
\tilde y_t
\end{pmatrix}
+\tilde y_t\log(p_t)+(n_t-\tilde y_t)\log(1-p_t)\right)
\end{align*}

2. La dérivée de la log-vraisemblance par rapport à $p_t$ s'écrit
$$\frac{\tilde y_t}{p_t}-\frac{n_t-\tilde y_t}{1-p_t}.$$
Cette dérivée s'annule pour
$$\widehat p_t=\frac{\tilde y_t}{n_t}.$$

3. On note $\widehat \beta$ l'EMV du modèle logistique et $p_{\widehat\beta}$ le vecteur qui contient les valeurs ajustées $p_{\widehat\beta}(x_t),t=1,\dots,T$. On a pour tout $\beta\in\mathbb R^p$ :
$$\mathcal L(Y,\beta)\leq\mathcal L(Y,\widehat\beta)=\mathcal L_{\text{sat}}(Y,p_{\widehat\beta})\leq L_{\text{sat}}(Y,\widehat p_t).$$

## Exercice 9

1.  
    a). Par définition $g^\star(x)=1$ si $\prob(Y=1|X=x)\geq 0.5$, $0$ sinon. L'erreur de Bayes vaut $L^\star=L(g^\star)=\prob(g^\star(X)\neq Y)$.

    b). On a
  \begin{align*}
\prob(g(X)\neq Y|X=x) & = 1-\left(\prob(g(X)=Y,g(X)=1|X=x)+\prob(g(X)=Y,g(X)=0|X=x)\right) \\
& = 1-\left(\ind_{g(x)=1}\prob(Y=1|X=x)+\ind_{g(x)=0}\prob(Y=0|X=x)\right) \\
& = 1-(\ind_{g(x)=1}\eta(x)+\ind_{g(x)=0}(1-\eta(x))).
  \end{align*}

    c). On déduit
\begin{align*}
\prob(g(X)\neq Y|X=x)- & \prob(g^\star(X)\neq Y|X=x) \\
& = \eta(x)\left(\ind_{g^\star(x)=1}-\ind_{g(x)=1}\right)+(1-\eta(x)) \left(\ind_{g^\star(x)=0}-\ind_{g(x)=0}\right) \\
& = (2\eta(x)-1) \left(\ind_{g^\star(x)=1}-\ind_{g(x)=1}\right) \\
& \geq 0
\end{align*}
puisque par définition $g^\star=1$ si et seulement si $\eta(x)\geq 1/2$.

    d). En intégrant l'inégalité précédente par rapport à la loi de $X$ on conclut
$$\prob(g(X)\neq Y)\geq \prob(g^\star(X)\neq Y).$$
2. Si $x\leq 0$ alors $\prob(Y=1|X=x)=\prob(U\leq 2)=1/5$ donc $g^\star(x)=0$. On montre de même que $g^\star(x)=1$ si $x>0$. Il reste à calculer l'erreur de Bayes :
$$L^\star=\prob(g^\star(X)\neq Y|X\leq 0)\prob(X\leq 0)+\prob(g^\star(X)\neq Y|X>0)\prob(X>0).$$
Or
$$\prob(g^\star(X)\neq Y|X\leq 0)=\prob(Y\neq 0|X\leq 0)=\prob(U\leq 2|X\leq 0)=\frac{1}{5}$$
et
$$\prob(g^\star(X)\neq Y|X>0)=\prob(Y\neq 1|X>0)=\prob(U<1|X\leq 0)=\frac{1}{10}.$$
On obtient 
$$L^\star=\frac{1}{5}\,\frac{1}{2}+\frac{1}{10}\,\frac{1}{2}=\frac{3}{20}.$$


## Exercice 10

1. On peut  estimer l'AUC en calculant, parmi les paires qui vérifient $(Y,Y')=(0,1)$, la proportion de paires qui vérifient $S(X)>S(X')$. Si on note
$$\mathcal I=\{(i,j),y_i=0,y_j=1\},$$
alors l'estimateur s'écrit
$$\widehat{\text{AUC}}(S)=\frac{1}{|\mathcal I|}\sum_{(i,j)\in\mathcal I}\ind_{S(x_i)>S(x_j)}.$$

2. 
    a). On importe les données et on les sépare en 2 échantillons.
  
    ```{r}
df <- read.csv("logit_ex6.csv")
set.seed(1234)
perm <- sample(nrow(df))
dapp <- df[perm[1:300],]
dval <- df[-perm[1:300],]
    ```

    b). Ajustement du modèle.
  
    ```{r}
mod <- glm(Y~.,data=dapp,family="binomial")
    ```

    c). Construction des scores.
  
    ```{r}
score <- predict(mod,newdata = dval)
    ```

    d). On peut maintenant calculer l'AUC.
  
    ```{r}
D0 <- which(dval$Y==0)
D1 <- which(dval$Y==1)
S0 <-score[D0]
S1 <- score[D1]
S01 <- expand.grid(S0=S0,S1=S1)
mean(S01$S1>S01$S0)
    ```
  
    e). On retrouve la valeur avec la fonction **auc** de **pROC**.
  
    ```{r message=FALSE, warning=FALSE}
library(pROC) 
auc(dval$Y,score)
    ```
  
  
  
## Exercice 11

1. On commence par importer les données et ajuster le modèle :
    ```{r}
artere <- read.table("artere.txt",sep=";",header=TRUE)
artere <- read.table("artere.txt",header=T)
modele <- glm(chd~age,data=artere,family=binomial)
B0 <- coef(modele)
OriginalDeviance <- modele$deviance
```


2. On fixe $\alpha$ à 0.05.

    ```{r}
alpha <- 0.05    
```


3. On effectue les opérations demandées :

    ```{r}
stderr <- summary(modele)$coefficients[, "Std. Error"]
delta <- sqrt(qchisq((1-alpha/4),df=1))* stderr[2] /5
grille <- B0[2]+(-10):10*delta
```

4.  On a
\begin{align*}
\mathcal D_1&=-2(\mathcal L(Y,\hat\beta)-\mathcal L_{sat})
  \end{align*}
La déviance avec l'offset \(K_i=x_i\beta_2^*\)  vaut 
  \begin{align*}
\mathcal D_o&=-2(\mathcal L(Y,K,\hat\beta_1)-\mathcal L_{sat})
  \end{align*}
où \(\hat \beta_1\) maximise \(\mathcal L(Y,K,\hat\beta_1)\) c'est à dire \(\mathcal L(Y,K,\hat\beta_1)=l(\beta_2^*)\)  et nous avons donc
  \begin{align*}
\mathcal D_o - \mathcal D_1= 2(\mathcal L(Y,\hat\beta)-\mathcal L(Y,K,\beta_1)= 2(\mathcal L(Y,\hat\beta)-l(\beta_2^*))=P(\beta_2^*).
  \end{align*}


5. On calcule **profil2**

    ```{r}
profil2 <- rep(0,length(grille))
for (k in 1:length(grille)) {
  modeleo <- glm(chd~1,family=binomial,offset=artere[,"age"]*grille[k],data=artere)
  profil2[k] <- modeleo$deviance - OriginalDeviance
}
```

6. On passe maintenant à **profil** :

    ```{r}
profil <- sign(-10:10)*sqrt(profil2)
```

7. On effectue l'interpolation avec la fonction **spline** :

    ```{r}
spline(x=profil,y=grille,xout=c(-sqrt(qchisq(1-alpha,1)),sqrt(qchisq(1-alpha,1))))$y
```

8. On obtient avec la fonction **confint** :

    ```{r message=FALSE, warning=FALSE}
confint(modele)
```






