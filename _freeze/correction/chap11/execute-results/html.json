{
  "hash": "60054b3fa154fb7cd9a73408d7eba61b",
  "result": {
    "markdown": "---\ntitle: \"11 Régression logistique\"\ntoc: true\n---\n\n\n::: {#exr-11-1 name=\"Question de cours\"}\n1.  A\n2.  A\n3.  B\n4.  A\n5.  A\n6.  A\n7.  B\n8.  A\n:::\n\n::: {#exr-11-2 name=\"Interprétation des coefficients\"}\n1.  On génère l'échantillon.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    n <- 100\n    set.seed(48967365)\n    X <- sample(c(\"A\",\"B\",\"C\"),100,replace=TRUE)\n    Y <- rep(0,n)\n    set.seed(487365)\n    Y[X==\"A\"] <- rbinom(sum(X==\"A\"),size=1,prob=0.95)\n    set.seed(4878365)\n    Y[X==\"B\"] <- rbinom(sum(X==\"B\"),size=1,prob=0.95)\n    set.seed(4653965)\n    Y[X==\"C\"] <- rbinom(sum(X==\"C\"),size=1,prob=0.05)\n    Y <- factor(Y)\n    donnees<-data.frame(Y,X)\n    ```\n    :::\n\n\n2.  On ajuste le modèle avec les contraintes par défaut.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    model1 <- glm(Y~X,data=donnees,family=binomial)\n    summary(model1)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    \n    Call:\n    glm(formula = Y ~ X, family = binomial, data = donnees)\n    \n    Coefficients:\n                Estimate Std. Error z value Pr(>|z|)    \n    (Intercept)   2.2336     0.6075   3.677 0.000236 ***\n    XB            0.6568     0.9470   0.694 0.487977    \n    XC           -5.6348     1.1842  -4.758 1.95e-06 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    (Dispersion parameter for binomial family taken to be 1)\n    \n        Null deviance: 129.489  on 99  degrees of freedom\n    Residual deviance:  44.218  on 97  degrees of freedom\n    AIC: 50.218\n    \n    Number of Fisher Scoring iterations: 6\n    ```\n    :::\n    :::\n\n\n    On obtient les résultats du **test de Wald** sur la nullité des paramètres $\\beta_0,\\beta_2$ et $\\beta_3$.\n\n3.  On change la modalité de référence.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    model2 <- glm(Y~C(X,base=3),data=donnees,family=binomial)\n    summary(model2)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    \n    Call:\n    glm(formula = Y ~ C(X, base = 3), family = binomial, data = donnees)\n    \n    Coefficients:\n                    Estimate Std. Error z value Pr(>|z|)    \n    (Intercept)       -3.401      1.017  -3.346  0.00082 ***\n    C(X, base = 3)A    5.635      1.184   4.758 1.95e-06 ***\n    C(X, base = 3)B    6.292      1.249   5.035 4.77e-07 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    \n    (Dispersion parameter for binomial family taken to be 1)\n    \n        Null deviance: 129.489  on 99  degrees of freedom\n    Residual deviance:  44.218  on 97  degrees of freedom\n    AIC: 50.218\n    \n    Number of Fisher Scoring iterations: 6\n    ```\n    :::\n    :::\n\n\n    On obtient les résultats du **test de Wald** sur la nullité des paramètres $\\beta_0,\\beta_1$ et $\\beta_2$.\n\n4.  On remarque que dans **model1** on accepte la nullité de $\\beta_2$ alors qu'on la rejette dans **model2**. Ceci est logique dans la mesure où ces tests dépendent de la contrainte identifiante choisie. Dans **model1** le test de nullité de $\\beta_2$ permet de vérifier si $B$ à un effet similaire à $A$ sur $Y$. Dans **model2**, on compare l'effet de $B$ à celui de $C$. On peut donc conclure $A$ et $B$ ont des effets proches sur $Y$ alors que $B$ et $C$ ont un impact différent. Ceci est logique vu la façon dont les données ont été générées.\n\n5.  Tester l'effet global de $X$ sur $Y$ revient à tester si les coefficients $\\beta_1,\\beta_2$ et $\\beta_3$ sont égaux, ce qui, compte tenu des contraintes revient à considérer les hypothèses nulles :\n\n    -   $\\beta_2=\\beta_3=0$ dans **model1** ;\n    -   $\\beta_1=\\beta_2=0$ dans **model2**.\n\n    On peut effectuer les tests de **Wald** ou du **rapport de vraisemblance**. On obtient les résultats du **rapport de vraisemblance** avec :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(car)\n    Anova(model1,type=3,test.statistic=\"LR\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Analysis of Deviance Table (Type III tests)\n    \n    Response: Y\n      LR Chisq Df Pr(>Chisq)    \n    X   85.271  2  < 2.2e-16 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    Anova(model2,type=3,test.statistic=\"LR\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Analysis of Deviance Table (Type III tests)\n    \n    Response: Y\n                   LR Chisq Df Pr(>Chisq)    \n    C(X, base = 3)   85.271  2  < 2.2e-16 ***\n    ---\n    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n    ```\n    :::\n    :::\n\n\n    On remarque ici que ces deux tests sont identiques : ils ne dépendent pas de la contrainte identifiante choisie.\n:::\n\n::: {#exr-11-3 name=\"Séparabilité\"}\n1.  On génère l'échantillon demandé.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    set.seed(1234)\n    X <- c(runif(50,-1,0),runif(50,0,1))\n    set.seed(5678)\n    Y <- c(rep(0,50),rep(1,50))\n    df <- data.frame(X,Y)\n    ```\n    :::\n\n\n2.  Le graphe s'obtient avec :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    beta <- seq(0,100,by=0.01)\n    log_vrais <- function(X,Y,beta){\n      LV <- rep(0,length(beta))\n      for (i in 1:length(beta)){\n        Pbeta <- exp(beta[i]*X)/(1+exp(beta[i]*X))\n        LV[i] <- sum(Y*X*beta[i]-log(1+exp(X*beta[i])))\n    #    gradln[i] <- t(Xb)%*%(Yb-Pbeta)\n      }\n      return(LV)\n    }\n    LL <- log_vrais(X,Y,beta)\n    plot(beta,LL,type=\"l\")\n    ```\n    \n    ::: {.cell-output-display}\n    ![](chap11_files/figure-html/unnamed-chunk-6-1.png){width=672}\n    :::\n    :::\n\n\n3.  On obtient un avertissement qui nous dit que l'algorithme d'optimisation n'a pas convergé.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    model <- glm(Y~X-1,data=df,family=\"binomial\")\n    model$coef\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n           X \n    1999.371 \n    ```\n    :::\n    :::\n\n\n4.  Le changement proposé supprime la séparabilité des données. On obtient bien un maximum fini pour cette nouvelle vraisemblance.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    Y1 <- Y;Y1[1] <- 1\n    LL1 <- log_vrais(X,Y1,beta)\n    plot(beta,LL1,type=\"l\")\n    ```\n    \n    ::: {.cell-output-display}\n    ![](chap11_files/figure-html/unnamed-chunk-8-1.png){width=672}\n    :::\n    \n    ```{.r .cell-code}\n    model1 <- glm(Y1~X-1,family=\"binomial\")\n    model1$coef\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n           X \n    10.17868 \n    ```\n    :::\n    :::\n\n:::\n\n::: {#exr-11-4 name=\"Matrice hessienne\"}\nLe gradient de la log-vraisemblance en $\\beta$ est donné par $\\nabla \\mathcal L(Y,\\beta)=X'(Y-P_\\beta)$. Sa $j$ème composante vaut $$\\frac{\\partial\\mathcal L}{\\partial\\beta_j}(\\beta)=\\sum_{i=1}^nx_{ij}(y_i-p_\\beta(x_i)).$$\n\nOn peut donc calculer la drivée par rapport à $\\beta_\\ell$ : \\begin{align*}\n\\frac{\\partial\\mathcal L}{\\partial\\beta_j\\partial\\beta_\\ell}(\\beta)= & \\frac{\\partial}{\\partial\\beta_\\ell}\\left[\n\\sum_{i=1}^nx_{ij}\\left(y_i-\\frac{\\exp(x_i'\\beta)}{1+\\exp(x_i'\\beta)}\\right)\\right] \\\\\n=& -\\sum_{i=1}^nx_{ij}x_{i\\ell}\\frac{\\exp(x_i'\\beta)}{[1+\\exp(x_i'\\beta)]^2} \\\\\n=& -\\sum_{i=1}^nx_{ij}x_{i\\ell}p_\\beta(x_i)(1-p_\\beta(x_i)).\n\\end{align*} Matriciellement on déduit donc que la hessienne vaut $$\\nabla^2\\mathcal L(Y,\\beta)=-X'W_\\beta X,$$ où $W_\\beta$ est la matrice $n\\times n$ diagonale dont le $i$ème terme de la diagonale vaut $p_\\beta(x_i)(1-p_\\beta(x_i))$. Par ailleurs, comme pour tout $i=1,\\dots,n$, on a $p_\\beta(x_i)(1-p_\\beta(x_i))>0$ et que $X$ est de plein rang, on déduit que $X'W_\\beta X$ est définie positive et par conséquent que la hessienne est définie négative.\n:::\n\n::: {#exr-11-5 name=\"Modèles avec R\"}\nOn importe les données\n\n\n::: {.cell}\n\n```{.r .cell-code}\npanne <- read.table(\"panne.txt\",header=T)\nhead(panne)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  etat age marque\n1    0   4      A\n2    0   2      C\n3    0   3      C\n4    0   9      B\n5    0   7      B\n6    0   6      A\n```\n:::\n:::\n\n\n1.  La commande\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    model <- glm(etat~.,data=panne,family=binomial)\n    model\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    \n    Call:  glm(formula = etat ~ ., family = binomial, data = panne)\n    \n    Coefficients:\n    (Intercept)          age      marqueB      marqueC  \n        0.47808      0.01388     -0.41941     -1.45608  \n    \n    Degrees of Freedom: 32 Total (i.e. Null);  29 Residual\n    Null Deviance:\t    45.72 \n    Residual Deviance: 43.5 \tAIC: 51.5\n    ```\n    :::\n    :::\n\n\n    ajuste le modèle $$\\log\\left(\\frac{p_\\beta(x)}{1-p_\\beta(x)}\\right)=\\beta_0+\\beta_1x_1+\\beta_2\\mathsf{1}_{x_2=B}+\\beta_3\\mathsf{1}_{x_2=C}$$ où $x_1$ et $x_2$ désigne respectivement les variables **age** et **marque**. On obtient les estimateurs avec\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    coef(model)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    (Intercept)         age     marqueB     marqueC \n     0.47808311  0.01388395 -0.41941071 -1.45608147 \n    ```\n    :::\n    :::\n\n\n2.  Il s'agit des tests de Wald pour tester l'effet des variables dans le modèle. Pour l'effet de marque, on va par exemple tester $$H_0:\\beta_2=\\beta_3=0\\quad\\text{contre}\\quad H_1:\\beta_2\\neq 0\\text{ ou }\\beta_3\\neq 0.$$ Sous $H_0$ la statistique de Wald suit une loi du $\\chi^2$ à 4-2=2 degrés de liberté. Pour le test de la variable **age** le nombre de degrés de liberté manquant est 1. On retrouve cela dans la sortie\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    library(car)\n    Anova(model,type=3,test.statistic=\"Wald\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Analysis of Deviance Table (Type III tests)\n    \n    Response: etat\n                Df  Chisq Pr(>Chisq)\n    (Intercept)  1 0.3294     0.5660\n    age          1 0.0218     0.8826\n    marque       2 1.9307     0.3809\n    ```\n    :::\n    :::\n\n\n3.  Il s'agit cette fois du test du rapport de vraisemblance. Les degrés de liberté manquants sont identiques.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    Anova(model,type=3,test.statistic=\"LR\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    Analysis of Deviance Table (Type III tests)\n    \n    Response: etat\n           LR Chisq Df Pr(>Chisq)\n    age     0.02189  1     0.8824\n    marque  2.09562  2     0.3507\n    ```\n    :::\n    :::\n\n\n4.  \n\n    a)  Le modèle s'écrit $$\\log\\left(\\frac{p_\\beta(x)}{1-p_\\beta(x)}\\right)=\\beta_0+\\beta_1\\mathsf{1}_{x_2=A}+\\beta_2\\mathsf{1}_{x_2=B}.$$\n\n    b)  Le modèle ajusté ici est \n$$\\log\\left(\\frac{p_\\beta(x)}{1-p_\\beta(x)}\\right)=\\gamma_0+\\gamma_1\\mathsf{1}_{x_2=B}+\\gamma_2\\mathsf{1}_{x_2=C}.$$ \nPar identification on a \n    $$\\begin{cases}\n        \\beta_0+\\beta_1=\\gamma_0 \\\\\n        \\beta_0+\\beta_2=\\gamma_0+\\gamma_1 \\\\\n        \\beta_0=\\gamma_0+\\gamma_2 \\\\\n        \\end{cases}\n        \\Longleftrightarrow\n        \\begin{cases}\n        \\beta_0=\\gamma_0+\\gamma_2 \\\\\n        \\beta_1=-\\gamma_2 \\\\\n        \\beta_2=\\gamma_1-\\gamma_2 \\\\\n        \\end{cases}\n        \\Longrightarrow\n        \\begin{cases}\n        \\widehat\\beta_0=-0.92 \\\\\n        \\widehat\\beta_1=1.48 \\\\\n        \\widehat\\beta_2=1.05 \\\\\n        \\end{cases}$$\n        On peut retrouver ces résultats avec\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        glm(etat~C(marque,base=3),data=panne,family=\"binomial\")\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        \n        Call:  glm(formula = etat ~ C(marque, base = 3), family = \"binomial\", \n            data = panne)\n        \n        Coefficients:\n                 (Intercept)  C(marque, base = 3)A  C(marque, base = 3)B  \n                     -0.9163                1.4759                1.0498  \n        \n        Degrees of Freedom: 32 Total (i.e. Null);  30 Residual\n        Null Deviance:\t    45.72 \n        Residual Deviance: 43.52 \tAIC: 49.52\n        ```\n        :::\n        :::\n\n\n5.  Il y a interaction si l'age agit différemment sur la panne en fonction de la marque.\n\n6.  Le modèle ajusté sur **R** est $$\\log\\left(\\frac{p_\\beta(x)}{1-p_\\beta(x)}\\right)=\\delta_0+\\delta_1\\mathsf{1}_{x_2=B}+\\delta_2\\mathsf{1}_{x_2=C}+\\delta_3x_1+\\delta_4x_1\\mathsf{1}_{x_2=B}+\\delta_5x_1\\mathsf{1}_{x_2=C}.$$ On obtient ainsi par identification : $$\\begin{cases}\n    \\alpha_0=\\delta_0\\\\\n    \\alpha_1=\\delta_3\\\\\n    \\beta_0=\\delta_0+\\delta_1\\\\\n    \\beta_1=\\delta_3+\\delta_4\\\\\n    \\gamma_0=\\delta_0+\\delta_2\\\\\n    \\gamma_1=\\delta_3+\\delta_5\n    \\end{cases}$$ On peut ainsi en déduire les valeurs des estimateurs que l'on peut retrouver avec la commande :\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    glm(etat~-1+marque+marque:age,data=panne,family=\"binomial\")\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    \n    Call:  glm(formula = etat ~ -1 + marque + marque:age, family = \"binomial\", \n        data = panne)\n    \n    Coefficients:\n        marqueA      marqueB      marqueC  marqueA:age  marqueB:age  marqueC:age  \n        0.23512      0.43375     -2.19633      0.05641     -0.05547      0.27228  \n    \n    Degrees of Freedom: 33 Total (i.e. Null);  27 Residual\n    Null Deviance:\t    45.75 \n    Residual Deviance: 42.62 \tAIC: 54.62\n    ```\n    :::\n    :::\n\n:::\n\n\n::: {#exr-11-6 name=\"Interprétation\"}\n\n::: {.cell}\n\n```{.r .cell-code}\ndf <- read.csv(\"../donnees/logit_ex6.csv\")\nmod <- glm(Y~.,data=df,family=binomial)\nmod1 <- glm(Y~X1,data=df,family=binomial)\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Y ~ ., family = binomial, data = df)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -0.57866    0.11926  -4.852 1.22e-06 ***\nX1          -0.19471    0.06556  -2.970  0.00298 ** \nX2           0.31899    0.04404   7.244 4.36e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 693.15  on 499  degrees of freedom\nResidual deviance: 618.26  on 497  degrees of freedom\nAIC: 624.26\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\nsummary(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Y ~ X1, family = binomial, data = df)\n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)\n(Intercept)  0.001092   0.089499   0.012    0.990\nX1          -0.020467   0.051733  -0.396    0.692\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 693.15  on 499  degrees of freedom\nResidual deviance: 692.99  on 498  degrees of freedom\nAIC: 696.99\n\nNumber of Fisher Scoring iterations: 3\n```\n:::\n:::\n\n\nOn remarque que la nullité du paramètre associé à **X1** est accepté dans le modèle avec uniquement **X1** alors qu'elle est refusée lorsqu'on considère **X1** et **X2** dans le modèle.\n\n:::\n\n::: {#exr-11-7 name=\"Tests à la main\"}\n1.  Le modèle s'écrit\n$$log\\left(\\frac{p_\\beta(x)}{1-p_\\beta(x)}\\right)=\\beta_0+\\beta_1x.$$\n\n2.  La log vraisemblance s'obtient avec\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    p <- c(0.76,0.4,0.6,0.89,0.35)\n    Y <- c(1,0,0,1,1)\n    L1 <- log(prod(p^Y*(1-p)^(1-Y)))\n    L1\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] -2.867909\n    ```\n    :::\n    :::\n\n\n3. \n  \n    a)  On calcule les écart-type des estimateurs\n    \n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        X1 <- c(0.47,-0.55,-0.01,1.07,-0.71)\n        X <- matrix(c(rep(1,5),X1),ncol=2)\n        W <- diag(p*(1-p))\n        SIG <- solve(t(X)%*%W%*%X)\n        sig <- sqrt(diag(SIG))\n        sig\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] 1.023252 1.744935\n        ```\n        :::\n        :::\n\n        \n        On en déduit les statistiques de test :\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        beta <- c(0.4383,1.5063)\n        beta/sig\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] 0.4283401 0.8632411\n        ```\n        :::\n        :::\n\n\n    b)  On peut faire le test de Wald et du rapport de vraisemblance. \n  \n    c)  La statistique de test vaut 0.8632411, on obtient donc la probabilité critique\n    \n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        2*(1-pnorm(0.8632411))\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] 0.3880049\n        ```\n        :::\n        :::\n\n\n        On peut également effectuer un test du rapport de vraisemblance. Le modèle null sans **X1** a pour log-vraisemblance\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        p0 <- 3/5\n        L0 <- log(prod(p0^Y*(1-p0)^(1-Y)))\n        L0\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] -3.365058\n        ```\n        :::\n        :::\n\n        \n        La statistique de test vaut donc\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        2*(L1-L0)\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] 0.9942984\n        ```\n        :::\n        :::\n\n\n        et la probabilité critique vaut\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        1-pchisq(2*(L1-L0),df=1)\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        [1] 0.3186941\n        ```\n        :::\n        :::\n\n        On peut retrouver (aux arrondis près) les résultats de l'exercice avec\n\n\n        ::: {.cell}\n        \n        ```{.r .cell-code}\n        X <- c(0.47,-0.55,-0.01,1.07,-0.71)\n        Y <- c(1,0,0,1,1)\n        df <- data.frame(X,Y)\n        model <- glm(Y~X,data=df,family=\"binomial\")\n        logLik(model)\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        'log Lik.' -2.898765 (df=2)\n        ```\n        :::\n        \n        ```{.r .cell-code}\n        Anova(model,type=3,test.statistic = \"Wald\")\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        Analysis of Deviance Table (Type III tests)\n        \n        Response: Y\n                    Df  Chisq Pr(>Chisq)\n        (Intercept)  1 0.1846     0.6675\n        X            1 0.7552     0.3848\n        ```\n        :::\n        \n        ```{.r .cell-code}\n        Anova(model,type=3,test.statistic = \"LR\")\n        ```\n        \n        ::: {.cell-output .cell-output-stdout}\n        ```\n        Analysis of Deviance Table (Type III tests)\n        \n        Response: Y\n          LR Chisq Df Pr(>Chisq)\n        X  0.93259  1     0.3342\n        ```\n        :::\n        :::\n\n\n:::\n\n::: {#exr-11-8 name=\"Vraisemblance du modèle saturé\"}\n1.  Les variables $(y_t,t=1,\\dots,y_T)$ étant indépendantes et de loi binomiales $B(n_t,p_t)$, la log-vraisemblance est donnée par\n\\begin{align*}\n\\mathcal L_{\\text{sat}}(Y,p)= & \\log\\left(\\prod_{t=1}^T\n\\begin{pmatrix}\nn_t\\\\\n\\tilde y_t\n\\end{pmatrix}\np_t^{\\tilde y_t}(1-p_t)^{n_t-\\tilde y_t}\\right) \\\\\n= &\n\\sum_{t=1}^T\\left(\\log\n\\begin{pmatrix}\nn_t\\\\\n\\tilde y_t\n\\end{pmatrix}\n+\\tilde y_t\\log(p_t)+(n_t-\\tilde y_t)\\log(1-p_t)\\right)\n\\end{align*}\n\n2.  La dérivée de la log-vraisemblance par rapport à $p_t$ s'écrit\n$$\\frac{\\tilde y_t}{p_t}-\\frac{n_t-\\tilde y_t}{1-p_t}.$$\nCette dérivée s'annule pour\n$$\\widehat p_t=\\frac{\\tilde y_t}{n_t}.$$\n\n3.  On note $\\widehat \\beta$ l'EMV du modèle logistique et $p_{\\widehat\\beta}$ le vecteur qui contient les valeurs ajustées $p_{\\widehat\\beta}(x_t),t=1,\\dots,T$. On a pour tout $\\beta\\in\\mathbb R^p$ :\n$$\\mathcal L(Y,\\beta)\\leq\\mathcal L(Y,\\widehat\\beta)=\\mathcal L_{\\text{sat}}(Y,p_{\\widehat\\beta})\\leq L_{\\text{sat}}(Y,\\widehat p_t).$$\n\n:::\n\n\n::: {#exr-11-9 name=\"Intervalle de confiance profilé\"}\n\n1.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    artere <- read.table(\"../donnees/artere.txt\",header=T)\n    modele <- glm(chd~age,data=artere,family=binomial)\n    B0 <- coef(modele)\n    OriginalDeviance <- modele$deviance\n    ```\n    :::\n\n\n2.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    alpha <- 0.05    \n    ```\n    :::\n\n\n3.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    stderr <- summary(modele)$coefficients[, \"Std. Error\"]\n    delta <- sqrt(qchisq((1-alpha/4),df=1))* stderr[2] /5\n    grille <- B0[2]+(-10):10*delta\n    ```\n    :::\n\n\n4.  On a\n  \\begin{align*}\n\\mathcal D_1&=-2(\\mathcal L(Y,\\hat\\beta)-\\mathcal L_{sat})\n  \\end{align*}\nPour celle avec l'offset $K_i=x_i\\beta_2^*$ elle vaut \n  \\begin{align*}\n\\mathcal D_o&=-2(\\mathcal L(Y,K,\\hat\\beta_1)-\\mathcal L_{sat})\n  \\end{align*}\noù $\\hat \\beta_1$ maximise $\\mathcal L(Y,K,\\hat\\beta_1)$ c'est à dire $\\mathcal L(Y,K,\\hat\\beta_1)=l(\\beta_2^*)$  et nous avons donc\n  \\begin{align*}\n\\mathcal D_o - \\mathcal D_1= 2(\\mathcal L(Y,\\hat\\beta)-\\mathcal L(Y,K,\\beta_1)= 2(\\mathcal L(Y,\\hat\\beta)-l(\\beta_2^*))=P(\\beta_2^*).\n  \\end{align*}\n\n5.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    profil2 <- rep(0,length(grille))\n    for (k in 1:length(grille)) {\n      modeleo <- glm(chd~1,family=binomial,offset=artere[,\"age\"]*grille[k],data=artere)\n      profil2[k] <- modeleo$deviance - OriginalDeviance\n    }\n    ```\n    :::\n\n    \n6.  \n    \n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    profil <- sign(-10:10)*sqrt(profil2)\n    ```\n    :::\n\n\n7.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    spline(x=profil,y=grille,xout=c(-sqrt(qchisq(1-alpha,1)),sqrt(qchisq(1-alpha,1))))$y\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.0669275 0.1620014\n    ```\n    :::\n    :::\n\n\n8.  \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    confint(modele)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n                      2.5 %     97.5 %\n    (Intercept) -7.72587162 -3.2461547\n    age          0.06693158  0.1620067\n    ```\n    :::\n    :::\n\n\n\n\n:::",
    "supporting": [
      "chap11_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}